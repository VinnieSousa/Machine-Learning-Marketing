{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5aedca7",
   "metadata": {},
   "source": [
    "# Projeto de Análise de Sentimentos - \"A Study in Scarlet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4313acc",
   "metadata": {},
   "source": [
    "### Livro por Arthur Conan Doyle, 1995."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2174e14f",
   "metadata": {},
   "source": [
    "A escolha do livro foi com base pela admiração ao icônico personagem Sherlock Holmes e suas façanhas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d73dff9",
   "metadata": {},
   "source": [
    "### Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96328dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a3c962",
   "metadata": {},
   "source": [
    "### Acesso e retirada do texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9780f721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto extraído e salvo com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Webscrapping do livro\n",
    "url = \"https://www.gutenberg.org/cache/epub/244/pg244-images.html\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Pega todo o corpo do texto\n",
    "text_div = soup.find(\"body\")\n",
    "text = text_div.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "# Salva o conteúdo em um arquivo .txt\n",
    "with open(\"A study in scarlet\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(text)\n",
    "\n",
    "print(\"Texto extraído e salvo com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce2870c",
   "metadata": {},
   "source": [
    "### Modelagem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ef1998",
   "metadata": {},
   "source": [
    "Ao fazer uma análise rápida do conteúdo do livro, notei que as falas estão apenas por “ ”, portanto defini que apenas o conteúdo entre estes caractéres serão retirados para análise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bbd99aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Orontes,\n",
      "\n",
      "2. Whatever have you been doing with yourself, Watson?\n",
      "\n",
      "3. You are as thin as a\n",
      "\n",
      "lath and as brown as a nut.\n",
      "\n",
      "4. Poor devil!\n",
      "\n",
      "5. What are you up to now?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"A study in scarlet\", \"r\", encoding=\"utf-8\") as f:\n",
    "    texto = f.read()\n",
    "\n",
    "# Extrai falas entre aspas\n",
    "falas = re.findall(r'“(.*?)”', texto, re.DOTALL)\n",
    "\n",
    "# Mostra algumas falas\n",
    "for i, fala in enumerate(falas[:5]):\n",
    "    print(f\"{i+1}. {fala}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb6ad75",
   "metadata": {},
   "source": [
    "### Análise de Sentimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e1dcf1",
   "metadata": {},
   "source": [
    "Utilizando a biblioteca do Hugging Face: Transformers, extraí a função \"Pipeline\" que já possui modelos pré-treinados como base para análise de sentimentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0657461e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Orontes,\n",
      "→ Sentimento: POSITIVE (confiança: 0.95)\n",
      "\n",
      "2. Whatever have you been doing with yourself, Watson?\n",
      "→ Sentimento: NEGATIVE (confiança: 0.99)\n",
      "\n",
      "3. You are as thin as a\n",
      "\n",
      "lath and as brown as a nut.\n",
      "→ Sentimento: NEGATIVE (confiança: 1.00)\n",
      "\n",
      "4. Poor devil!\n",
      "→ Sentimento: NEGATIVE (confiança: 0.99)\n",
      "\n",
      "5. What are you up to now?\n",
      "→ Sentimento: POSITIVE (confiança: 1.00)\n",
      "\n",
      "6. Looking for lodgings,\n",
      "→ Sentimento: NEGATIVE (confiança: 0.99)\n",
      "\n",
      "7. Trying to solve the problem as to whether\n",
      "\n",
      "it is possible to get comfortable rooms at a reasonable price.\n",
      "→ Sentimento: NEGATIVE (confiança: 1.00)\n",
      "\n",
      "8. That’s a strange thing,\n",
      "→ Sentimento: NEGATIVE (confiança: 0.72)\n",
      "\n",
      "9. you are the second man to-day\n",
      "\n",
      "that has used that expression to me.\n",
      "→ Sentimento: POSITIVE (confiança: 1.00)\n",
      "\n",
      "10. And who was the first?\n",
      "→ Sentimento: NEGATIVE (confiança: 0.99)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analisador = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Analisa as primeiras falas\n",
    "for i, fala in enumerate(falas[:10]):\n",
    "    resultado = analisador(fala)[0]\n",
    "    print(f\"{i+1}. {fala}\")\n",
    "    print(f\"→ Sentimento: {resultado['label']} (confiança: {resultado['score']:.2f})\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57069755",
   "metadata": {},
   "source": [
    "Para o próximo passo deste projeto, filtrarei apenas as falas de Sherlock Holmes, na tentativa de conseguir algum traço de sua personalidade. Futuramente, buscarei criar uma Inteligencia Artificial que simule sua personalidade e consiga responder prompts com base nisso."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
